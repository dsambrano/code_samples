#     # Compare model prediction to observed response
#     err <- (choice == 'Reference') * log(p) + (1 - (choice == 'Reference')) * log(1-p)
#
#     # Objective function to be minimized
#     sumError <- -sum(err)
#     return(sumError)
# }
# pracma::fminsearch(pChooseLottery, x0=c(1, 0, 1), data = singlePartData)
# # library(stats4)
# # mle(minuslogl = pChooseLottery, start= list(alpha = .1, Beta=.2, gamma = 1))
# m <- length(p)
# SVfixed <- SubjectiveValue(alpha, beta, rep(1,m), rep(0,m), rep(5,m))
# SVlottery <- SubjectiveValue(alpha, beta, p, A, V)
# g <- 1/(1 + exp(gamma*(SVfixed - SVlottery))) # Sigmoid
money <- seq(0,71,length.out = 1000)
for (i in 1:length(participants)){
pChoose <- matrix(NA,1,3*length(money))
count <- 1
S <- seq(1,length(pChoose)+1, length(money))
for (p in unique(longformat$probs)){
pChoose[S[count]:(S[count+1]-1)] <- choicePredict(parMat[i,1], parMat[i,2], parMat[i,3],
rep(p,length(money)),rep(0,length(money)),
money) # (alpha, beta, gamma, p, A, V)
count <- count + 1
}
## This for how PROBABILITY CHANGES
predictData <- data.frame(money=c(money,money, money), probability=c(pChoose),
probs=factor(rep(unique(longformat$probs),each=length(money))))
singlePartData <- subset(longformat, longformat$observer == participants[i])
data <- subset(singlePartData, singlePartData$ambigs == 0)
agData <- aggregate(data$choice,list(data$vals,data$probs), mean, na.action = na.omit)
agData$Group.2 <- factor(agData$Group.2)
Modelplot <- ggplot(predictData, aes(x=money, y=probability, colour=probs)) +
geom_line() +
geom_point(data=agData, aes(x=Group.1,y=x, colour=Group.2), position=position_jitterdodge(.5)) +
scale_color_brewer(palette="Blues") +
labs(title = paste0('Participant: ', participants[i]),
subtitle = TeX(sprintf("$\\alpha = %.3f$; $\\beta = %1.3f$", parMat[i,1],
parMat[i,2])),
colour = "Probs", y = expression('P(Choose Lottery)'), x = 'Money') +
apatheme
print(Modelplot)
## This for how AMBIGUITY CHANGES
pChoose <- matrix(NA,1,3*length(money))
count <- 1
S <- seq(1,length(pChoose)+1, length(money))
uAmbigs <- unique(longformat$ambig)[-which(unique(longformat$ambig) == 0)]
uAmbigs <- uAmbigs[order(uAmbigs)]
for (p in uAmbigs){
pChoose[S[count]:(S[count+1]-1)] <- choicePredict(parMat[i,1], parMat[i,2], parMat[i,3],
rep(.5,length(money)), # p: probablity
rep(p,length(money)), # A: ambiguity from the for loop
money) # (alpha, beta, gamma, p, A, V)
count <- count + 1
}
# Predicting data
predictData <- data.frame(money=c(money,money, money), probability=c(pChoose),
probs=factor(rep(uAmbigs,each=length(money))))
singlePartData <- subset(longformat, longformat$observer == participants[i])
data <- subset(singlePartData, singlePartData$ambigs != 0)
agData <- aggregate(data$choice,list(data$vals,data$ambig), mean, na.action = na.omit)
agData$Group.2 <- factor(agData$Group.2)
# Plotting data
Modelplot <- ggplot(predictData, aes(x=money, y=probability, colour=probs)) +
geom_line() +
geom_point(data=agData, aes(x=Group.1,y=x, colour=Group.2),position=position_jitterdodge(.5)) +
scale_color_brewer(palette="Reds") +
labs(title = paste0('Participant: ', participants[i]),
subtitle = TeX(sprintf("$\\alpha = %.3f$; $\\beta = %1.3f$", parMat[i,1],
parMat[i,2])),
colour = "Ambiguity", y = expression('P(Choose Lottery)'), x = 'Money') +
apatheme
print(Modelplot)
}
numParams <- 3
reliabilityParMat <- matrix(NA,length(participants)*2,numParams+3)
for (i in 1:length(participants)) {
for (j in 1:0) {
singlePartData <- subset(longformat, longformat$observer == participants[i])
if (j) {
uy <- singlePartData$choice[1:(nrow(singlePartData)/2)]
data <- singlePartData[1:(nrow(singlePartData)/2),]
}else{
uy <- singlePartData$choice[((nrow(singlePartData)/2)+1):nrow(singlePartData)]
data <- singlePartData[((nrow(singlePartData)/2)+1):nrow(singlePartData),]
}
#Intial theta
initial_theta1 <- rep(0,numParams) # Default values used when no knowledge
initial_theta2 <- c(1,0,1) # This is with neurtal preferences and is a better starting point
#Cost at inital theta
#cost(initial_theta)
# Derive theta using gradient descent using optim function: Using Multiple starting points
# Should probably use more and find a better way to optimize
theta_optim1 <- optim(par=initial_theta1,fn=cost, control = list(maxit=1000))
theta_optim2 <- optim(par=initial_theta2,fn=cost, control = list(maxit=1000))
# Choosing the estimates that best fit the data
if (theta_optim1$value < theta_optim2$value){
theta_optim <- theta_optim1
}else{
theta_optim <- theta_optim2
}
#set theta
reliabilityParMat[(i*2 - j),1:numParams] <- theta_optim$par
# theta_optim$par
# theta <- theta_optim$par
#cost at optimal value of the theta
reliabilityParMat[(i*2 - j),numParams+1] <- theta_optim$value
# theta_optim$value
# Counts and convergence
reliabilityParMat[(i*2 - j),numParams+2] <- theta_optim$counts[1]
reliabilityParMat[(i*2 - j),numParams+3] <- theta_optim$convergence
}
}
# See cost function to know what the order of the params is
# currently its: 1 = alpha and 2 = beta
colnames(reliabilityParMat) <- c('alpha', 'beta','gamma','minVal', 'counts','convergence')
reliabilityParMat
rcorr(reliabilityParMat[seq(1,2*length(participants),2),1:3],reliabilityParMat[seq(2,2*length(participants),2),1:3])
print('First half to whole')
rcorr(reliabilityParMat[seq(1,2*length(participants),2),1:3], parMat[,1:3])
print('Second half to whole')
rcorr(reliabilityParMat[seq(2,2*length(participants),2),1:3], parMat[,1:3])
numParams <- 3
reliabilityParMat <- matrix(NA,length(participants)*4,numParams+4)
for (i in 1:length(participants)) {
for (j in 3:0) {
singlePartData <- subset(longformat, longformat$observer == participants[i])
if (j == 3) {
uy <- singlePartData$choice[1:(nrow(singlePartData)/4)]
data <- singlePartData[1:(nrow(singlePartData)/4),]
}else if (j == 2){
uy <- singlePartData$choice[(nrow(singlePartData)/4 + 1):(nrow(singlePartData)/2)]
data <- singlePartData[(nrow(singlePartData)/4 + 1):(nrow(singlePartData)/2),]
}else if (j == 1){
uy <- singlePartData$choice[((nrow(singlePartData)/2)+1):(nrow(singlePartData)/4*3)]
data <- singlePartData[((nrow(singlePartData)/2)+1):(nrow(singlePartData)/4*3),]
}else{
uy <- singlePartData$choice[((nrow(singlePartData)/4*3)+1):nrow(singlePartData)]
data <- singlePartData[((nrow(singlePartData)/4*3)+1):nrow(singlePartData),]
}
#Intial theta
initial_theta1 <- rep(0,numParams) # Default values used when no knowledge
initial_theta2 <- c(1,0,1) # This is with neurtal preferences and is a better starting point
#Cost at inital theta
#cost(initial_theta)
# Derive theta using gradient descent using optim function: Using Multiple starting points
# Should probably use more and find a better way to optimize
theta_optim1 <- optim(par=initial_theta1,fn=cost, control = list(maxit=1000))
theta_optim2 <- optim(par=initial_theta2,fn=cost, control = list(maxit=1000))
# # Choosing the estimates that best fit the data
# if (theta_optim1$value < theta_optim2$value){
#   theta_optim <- theta_optim1
# }else{
#   theta_optim <- theta_optim2
# }
# Choosing the estimates that best fit the data
if (theta_optim1$value < theta_optim2$value){
theta_optim <- theta_optim1
reliabilityParMat[(i*4 - j),numParams+4] <- 1
}else{
theta_optim <- theta_optim2
reliabilityParMat[(i*4 - j),numParams+4] <- 2
}
if(any(theta_optim1$par <= -8) | any(theta_optim1$par >= +8)){
theta_optim <- theta_optim2
reliabilityParMat[(i*4 - j),numParams+4] <- 2
if ((any(theta_optim$par <= -8) | any(theta_optim$par >= +8))){
theta_optim <- theta_optim1
# theta_optim$par <- rep(NA,numParams)
theta_optim$convergence <- NA
reliabilityParMat[(i*4 - j),numParams+4] <- 21
}
}else if(any(theta_optim2$par <= -8) | any(theta_optim2$par >= +8)) {
theta_optim <- theta_optim1
reliabilityParMat[(i*4 - j),numParams+4] <- 1
if ((any(theta_optim$par <= -8) | any(theta_optim$par >= +8))){
theta_optim <- theta_optim1
# theta_optim$par <- rep(NA,numParams)
theta_optim$convergence <- NA
reliabilityParMat[(i*4 - j),numParams+4] <- 12
}
}
#set theta
reliabilityParMat[(i*4 - j),1:numParams] <- theta_optim$par
# theta_optim$par
# theta <- theta_optim$par
#cost at optimal value of the theta
reliabilityParMat[(i*4 - j),numParams+1] <- theta_optim$value
# theta_optim$value
# Counts and convergence
reliabilityParMat[(i*4 - j),numParams+2] <- theta_optim$counts[1]
reliabilityParMat[(i*4 - j),numParams+3] <- theta_optim$convergence
}
}
# See cost function to know what the order of the params is
# currently its: 1 = alpha and 2 = beta
colnames(reliabilityParMat) <- c('alpha', 'beta','gamma','minVal', 'counts','convergence', 'paramSet')
reliabilityParMat
noConverge <- which(is.na(reliabilityParMat[,6]))
Q1 <- seq(1,4*length(participants),4); Q1 <- setdiff(Q1, noConverge)
Q2 <- seq(2,4*length(participants),4); Q2 <- setdiff(Q2, noConverge)
Q3 <- seq(3,4*length(participants),4); Q3 <- setdiff(Q3, noConverge)
Q4 <- seq(4,4*length(participants),4); Q4 <- setdiff(Q4, noConverge)
Q12 <- intersect(Q1+1,Q2)
Q34 <- intersect(Q3+1,Q4)
Q23 <- intersect(Q2+1,Q3)
cat('Quarter 1 vs. Quarter 2')
rcorr(reliabilityParMat[Q12-1,1:3],
reliabilityParMat[Q12,1:3])
cat('Quarter 2 vs. Quarter 3')
rcorr(reliabilityParMat[Q23-1,1:3],
reliabilityParMat[Q23,1:3])
cat('Quarter 3 vs. Quarter 4')
rcorr(reliabilityParMat[Q34-1,1:3],
reliabilityParMat[Q34,1:3])
# print('First half to whole')
# rcorr(reliabilityParMat[seq(1,2*length(participants),2),1:3], parMat[,1:3])
# print('Second half to whole')
# rcorr(reliabilityParMat[seq(2,2*length(participants),2),1:3], parMat[,1:3])
Quantile1 <- c(65,62,60,59,55,54,34,32:30)
corMat <- matrix(NA,length(Quantile1),numParams)
quarterD <- nrow(singlePartData)/4 +20
for (k in 1:length(Quantile1)){
reliabilityParMat <- matrix(NA,length(participants)*4,numParams+4)
for (i in 1:length(participants)) {
for (j in 3:0) {
singlePartData <- subset(longformat, longformat$observer == participants[i])
if (j == 3) {
uy <- singlePartData$choice[1:Quantile1[k]]
data <- singlePartData[1:Quantile1[k],]
}else if (j == 2){
uy <- singlePartData$choice[(Quantile1[k] + 1):(Quantile1[k]+quarterD)]
data <- singlePartData[(Quantile1[k] + 1):(Quantile1[k]+quarterD),]
}else if (j == 1){
uy <- singlePartData$choice[((nrow(singlePartData)/2)+1):(nrow(singlePartData)/4*3)]
data <- singlePartData[((Quantile1[k]+quarterD)+1):(Quantile1[k]+quarterD+quarterD),]
}else{
uy <- singlePartData$choice[(Quantile1[k]+quarterD+quarterD+1):nrow(singlePartData)]
data <- singlePartData[(Quantile1[k]+quarterD+quarterD+1):nrow(singlePartData),]
}
#Intial theta
initial_theta1 <- rep(0,numParams) # Default values used when no knowledge
initial_theta2 <- c(1,0,1) # This is with neurtal preferences and is a better starting point
#Cost at inital theta
#cost(initial_theta)
# Derive theta using gradient descent using optim function: Using Multiple starting points
# Should probably use more and find a better way to optimize
theta_optim1 <- optim(par=initial_theta1,fn=cost, control = list(maxit=10000))
theta_optim2 <- optim(par=initial_theta2,fn=cost, control = list(maxit=10000))
# # Choosing the estimates that best fit the data
# if (theta_optim1$value < theta_optim2$value){
#   theta_optim <- theta_optim1
# }else{
#   theta_optim <- theta_optim2
# }
# Choosing the estimates that best fit the data
if (theta_optim1$value < theta_optim2$value){
theta_optim <- theta_optim1
reliabilityParMat[(i*4 - j),numParams+4] <- 1
}else{
theta_optim <- theta_optim2
reliabilityParMat[(i*4 - j),numParams+4] <- 2
}
if(any(theta_optim1$par <= -8) | any(theta_optim1$par >= +8)){
theta_optim <- theta_optim2
reliabilityParMat[(i*4 - j),numParams+4] <- 2
if ((any(theta_optim$par <= -8) | any(theta_optim$par >= +8))){
theta_optim <- theta_optim1
# theta_optim$par <- rep(NA,numParams)
theta_optim$convergence <- NA
reliabilityParMat[(i*4 - j),numParams+4] <- 21
}
}else if(any(theta_optim2$par <= -8) | any(theta_optim2$par >= +8)) {
theta_optim <- theta_optim1
reliabilityParMat[(i*4 - j),numParams+4] <- 1
if ((any(theta_optim$par <= -8) | any(theta_optim$par >= +8))){
theta_optim <- theta_optim1
# theta_optim$par <- rep(NA,numParams)
theta_optim$convergence <- NA
reliabilityParMat[(i*4 - j),numParams+4] <- 12
}
}
#set theta
reliabilityParMat[(i*4 - j),1:numParams] <- theta_optim$par
# theta_optim$par
# theta <- theta_optim$par
#cost at optimal value of the theta
reliabilityParMat[(i*4 - j),numParams+1] <- theta_optim$value
# theta_optim$value
# Counts and convergence
reliabilityParMat[(i*4 - j),numParams+2] <- theta_optim$counts[1]
reliabilityParMat[(i*4 - j),numParams+3] <- theta_optim$convergence
}
}
# See cost function to know what the order of the params is
# currently its: 1 = alpha and 2 = beta
colnames(reliabilityParMat) <- c('alpha', 'beta','gamma','minVal', 'counts','convergence', 'paramSet')
reliabilityParMat
noConverge <- which(is.na(reliabilityParMat[,6]))
Q1 <- seq(1,4*length(participants),4); Q1 <- setdiff(Q1, noConverge)
Q2 <- seq(2,4*length(participants),4); Q2 <- setdiff(Q2, noConverge)
Q3 <- seq(3,4*length(participants),4); Q3 <- setdiff(Q3, noConverge)
Q4 <- seq(4,4*length(participants),4); Q4 <- setdiff(Q4, noConverge)
Q12 <- intersect(Q1+1,Q2)
Q34 <- intersect(Q3+1,Q4)
Q23 <- intersect(Q2+1,Q3)
temp <- rcorr(reliabilityParMat[Q23-1,1:3],reliabilityParMat[Q23,1:3])
corMat[k, 1:3] <- temp$r[cbind(c(4,5,6),c(1,2,3))]
}
k
Quantile1 <- c(65,62,60,59,55,54,34,32:30)
corMat <- matrix(NA,length(Quantile1),numParams)
quarterD <- nrow(singlePartData)/4
for (k in 1:length(Quantile1)){
reliabilityParMat <- matrix(NA,length(participants)*4,numParams+4)
for (i in 1:length(participants)) {
for (j in 3:0) {
singlePartData <- subset(longformat, longformat$observer == participants[i])
if (j == 3) {
uy <- singlePartData$choice[1:Quantile1[k]]
data <- singlePartData[1:Quantile1[k],]
}else if (j == 2){
uy <- singlePartData$choice[(Quantile1[k] + 1):(Quantile1[k]+quarterD)]
data <- singlePartData[(Quantile1[k] + 1):(Quantile1[k]+quarterD),]
}else if (j == 1){
uy <- singlePartData$choice[((Quantile1[k]+quarterD)+1):(Quantile1[k]+quarterD+quarterD)]
data <- singlePartData[((Quantile1[k]+quarterD)+1):(Quantile1[k]+quarterD+quarterD),]
}else{
uy <- singlePartData$choice[(Quantile1[k]+quarterD+quarterD+1):nrow(singlePartData)]
data <- singlePartData[(Quantile1[k]+quarterD+quarterD+1):nrow(singlePartData),]
}
#Intial theta
initial_theta1 <- rep(0,numParams) # Default values used when no knowledge
initial_theta2 <- c(1,0,1) # This is with neurtal preferences and is a better starting point
#Cost at inital theta
#cost(initial_theta)
# Derive theta using gradient descent using optim function: Using Multiple starting points
# Should probably use more and find a better way to optimize
theta_optim1 <- optim(par=initial_theta1,fn=cost, control = list(maxit=10000))
theta_optim2 <- optim(par=initial_theta2,fn=cost, control = list(maxit=10000))
# # Choosing the estimates that best fit the data
# if (theta_optim1$value < theta_optim2$value){
#   theta_optim <- theta_optim1
# }else{
#   theta_optim <- theta_optim2
# }
# Choosing the estimates that best fit the data
if (theta_optim1$value < theta_optim2$value){
theta_optim <- theta_optim1
reliabilityParMat[(i*4 - j),numParams+4] <- 1
}else{
theta_optim <- theta_optim2
reliabilityParMat[(i*4 - j),numParams+4] <- 2
}
if(any(theta_optim1$par <= -8) | any(theta_optim1$par >= +8)){
theta_optim <- theta_optim2
reliabilityParMat[(i*4 - j),numParams+4] <- 2
if ((any(theta_optim$par <= -8) | any(theta_optim$par >= +8))){
theta_optim <- theta_optim1
# theta_optim$par <- rep(NA,numParams)
theta_optim$convergence <- NA
reliabilityParMat[(i*4 - j),numParams+4] <- 21
}
}else if(any(theta_optim2$par <= -8) | any(theta_optim2$par >= +8)) {
theta_optim <- theta_optim1
reliabilityParMat[(i*4 - j),numParams+4] <- 1
if ((any(theta_optim$par <= -8) | any(theta_optim$par >= +8))){
theta_optim <- theta_optim1
# theta_optim$par <- rep(NA,numParams)
theta_optim$convergence <- NA
reliabilityParMat[(i*4 - j),numParams+4] <- 12
}
}
#set theta
reliabilityParMat[(i*4 - j),1:numParams] <- theta_optim$par
# theta_optim$par
# theta <- theta_optim$par
#cost at optimal value of the theta
reliabilityParMat[(i*4 - j),numParams+1] <- theta_optim$value
# theta_optim$value
# Counts and convergence
reliabilityParMat[(i*4 - j),numParams+2] <- theta_optim$counts[1]
reliabilityParMat[(i*4 - j),numParams+3] <- theta_optim$convergence
}
}
# See cost function to know what the order of the params is
# currently its: 1 = alpha and 2 = beta
colnames(reliabilityParMat) <- c('alpha', 'beta','gamma','minVal', 'counts','convergence', 'paramSet')
reliabilityParMat
noConverge <- which(is.na(reliabilityParMat[,6]))
Q1 <- seq(1,4*length(participants),4); Q1 <- setdiff(Q1, noConverge)
Q2 <- seq(2,4*length(participants),4); Q2 <- setdiff(Q2, noConverge)
Q3 <- seq(3,4*length(participants),4); Q3 <- setdiff(Q3, noConverge)
Q4 <- seq(4,4*length(participants),4); Q4 <- setdiff(Q4, noConverge)
Q12 <- intersect(Q1+1,Q2)
Q34 <- intersect(Q3+1,Q4)
Q23 <- intersect(Q2+1,Q3)
temp <- rcorr(reliabilityParMat[Q23-1,1:3],reliabilityParMat[Q23,1:3])
corMat[k, 1:3] <- temp$r[cbind(c(4,5,6),c(1,2,3))]
}
corData <- data.frame(cor=c(corMat)^2,type=factor(rep(1:numParams,each=length(Quantile1)), labels = c('alpha', 'beta', 'gamma')),
train=Quantile1)
corData2 <- data.frame(cor=rowMeans(corMat)^2, train=Quantile1)
ggplot(corData, aes(x=train, y=cor, color=type)) +
geom_point() + geom_line() + scale_y_continuous(limits = c(0,1)) +
apatheme
ggplot(corData2, aes(x=train, y=cor)) +
geom_point() + geom_line() + scale_y_continuous(limits = c(0,1)) +
apatheme
seq(50,10,10)
help(seq)
seq(50,10,-10)
Quantile1 <- c(62,seq(50,10,-10))#c(65,62,60,59,55,54,34,32:30)
corMat <- matrix(NA,length(Quantile1),numParams)
quarterD <- nrow(singlePartData)/4
for (k in 1:length(Quantile1)){
reliabilityParMat <- matrix(NA,length(participants)*4,numParams+4)
for (i in 1:length(participants)) {
for (j in 3:0) {
singlePartData <- subset(longformat, longformat$observer == participants[i])
if (j == 3) {
uy <- singlePartData$choice[1:Quantile1[k]]
data <- singlePartData[1:Quantile1[k],]
}else if (j == 2){
uy <- singlePartData$choice[(Quantile1[k] + 1):(Quantile1[k]+quarterD)]
data <- singlePartData[(Quantile1[k] + 1):(Quantile1[k]+quarterD),]
}else if (j == 1){
uy <- singlePartData$choice[((Quantile1[k]+quarterD)+1):(Quantile1[k]+quarterD+quarterD)]
data <- singlePartData[((Quantile1[k]+quarterD)+1):(Quantile1[k]+quarterD+quarterD),]
}else{
uy <- singlePartData$choice[(Quantile1[k]+quarterD+quarterD+1):nrow(singlePartData)]
data <- singlePartData[(Quantile1[k]+quarterD+quarterD+1):nrow(singlePartData),]
}
#Intial theta
initial_theta1 <- rep(0,numParams) # Default values used when no knowledge
initial_theta2 <- c(1,0,1) # This is with neurtal preferences and is a better starting point
#Cost at inital theta
#cost(initial_theta)
# Derive theta using gradient descent using optim function: Using Multiple starting points
# Should probably use more and find a better way to optimize
theta_optim1 <- optim(par=initial_theta1,fn=cost, control = list(maxit=10000))
theta_optim2 <- optim(par=initial_theta2,fn=cost, control = list(maxit=10000))
# # Choosing the estimates that best fit the data
# if (theta_optim1$value < theta_optim2$value){
#   theta_optim <- theta_optim1
# }else{
#   theta_optim <- theta_optim2
# }
# Choosing the estimates that best fit the data
if (theta_optim1$value < theta_optim2$value){
theta_optim <- theta_optim1
reliabilityParMat[(i*4 - j),numParams+4] <- 1
}else{
theta_optim <- theta_optim2
reliabilityParMat[(i*4 - j),numParams+4] <- 2
}
if(any(theta_optim1$par <= -8) | any(theta_optim1$par >= +8)){
theta_optim <- theta_optim2
reliabilityParMat[(i*4 - j),numParams+4] <- 2
if ((any(theta_optim$par <= -8) | any(theta_optim$par >= +8))){
theta_optim <- theta_optim1
# theta_optim$par <- rep(NA,numParams)
theta_optim$convergence <- NA
reliabilityParMat[(i*4 - j),numParams+4] <- 21
}
}else if(any(theta_optim2$par <= -8) | any(theta_optim2$par >= +8)) {
theta_optim <- theta_optim1
reliabilityParMat[(i*4 - j),numParams+4] <- 1
if ((any(theta_optim$par <= -8) | any(theta_optim$par >= +8))){
theta_optim <- theta_optim1
# theta_optim$par <- rep(NA,numParams)
theta_optim$convergence <- NA
reliabilityParMat[(i*4 - j),numParams+4] <- 12
}
}
#set theta
reliabilityParMat[(i*4 - j),1:numParams] <- theta_optim$par
# theta_optim$par
# theta <- theta_optim$par
#cost at optimal value of the theta
reliabilityParMat[(i*4 - j),numParams+1] <- theta_optim$value
# theta_optim$value
# Counts and convergence
reliabilityParMat[(i*4 - j),numParams+2] <- theta_optim$counts[1]
reliabilityParMat[(i*4 - j),numParams+3] <- theta_optim$convergence
}
}
# See cost function to know what the order of the params is
# currently its: 1 = alpha and 2 = beta
colnames(reliabilityParMat) <- c('alpha', 'beta','gamma','minVal', 'counts','convergence', 'paramSet')
reliabilityParMat
noConverge <- which(is.na(reliabilityParMat[,6]))
Q1 <- seq(1,4*length(participants),4); Q1 <- setdiff(Q1, noConverge)
Q2 <- seq(2,4*length(participants),4); Q2 <- setdiff(Q2, noConverge)
Q3 <- seq(3,4*length(participants),4); Q3 <- setdiff(Q3, noConverge)
Q4 <- seq(4,4*length(participants),4); Q4 <- setdiff(Q4, noConverge)
Q12 <- intersect(Q1+1,Q2)
Q34 <- intersect(Q3+1,Q4)
Q23 <- intersect(Q2+1,Q3)
temp <- rcorr(reliabilityParMat[Q23-1,1:3],reliabilityParMat[Q23,1:3])
corMat[k, 1:3] <- temp$r[cbind(c(4,5,6),c(1,2,3))]
}
corData <- data.frame(cor=c(corMat)^2,type=factor(rep(1:numParams,each=length(Quantile1)), labels = c('alpha', 'beta', 'gamma')),
train=Quantile1)
corData2 <- data.frame(cor=rowMeans(corMat)^2, train=Quantile1)
ggplot(corData, aes(x=train, y=cor, color=type)) +
geom_point() + geom_line() + scale_y_continuous(limits = c(0,1)) +
apatheme
ggplot(corData2, aes(x=train, y=cor)) +
geom_point() + geom_line() + scale_y_continuous(limits = c(0,1)) +
apatheme
install.packages("reticulate")
